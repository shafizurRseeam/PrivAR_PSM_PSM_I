{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8451295-7c96-4f12-af07-13786fa600e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete. Generated 5 copies per CSV.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# USER INPUTS\n",
    "# =========================\n",
    "INPUT_DIR  = r\"C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\original\\geotrace\\security\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\original\\geotrace\\privacy\"\n",
    "NUM_COPIES = 5        # augmentation factor\n",
    "COPY_COL   = \"copy\"   # name of the new column\n",
    "\n",
    "# =========================\n",
    "# CREATE OUTPUT DIRECTORY\n",
    "# =========================\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# PROCESS FILES\n",
    "# =========================\n",
    "for filename in os.listdir(INPUT_DIR):\n",
    "    if not filename.lower().endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    input_path = os.path.join(INPUT_DIR, filename)\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "\n",
    "    for i in range(1, NUM_COPIES + 1):\n",
    "        df_copy = df.copy()\n",
    "        df_copy[COPY_COL] = i\n",
    "\n",
    "        output_filename = f\"{base_name}_copy{i}.csv\"\n",
    "        output_path = os.path.join(OUTPUT_DIR, output_filename)\n",
    "\n",
    "        df_copy.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Augmentation complete. Generated {NUM_COPIES} copies per CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4943483-c135-492a-858d-009ed76298f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Merged plm/eps01: 63771 rows -> C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\plm\\merged_geotrace_plm_delta_3_Noisy_threshold_5_eps01\\merged_geotrace_plm_delta_3_Noisy_threshold_5_eps01.csv\n",
      "[SKIP] Missing folder: C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\plm\\eps05\n",
      "[OK] Merged psm/eps01: 63771 rows -> C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\psm\\merged_geotrace_psm_delta_3_Noisy_threshold_5_eps01\\merged_geotrace_psm_delta_3_Noisy_threshold_5_eps01.csv\n",
      "[SKIP] Missing folder: C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\psm\\eps05\n",
      "[OK] Merged psmi/eps01: 63771 rows -> C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\psmi\\merged_geotrace_psmi_delta_3_Noisy_threshold_5_eps01\\merged_geotrace_psmi_delta_3_Noisy_threshold_5_eps01.csv\n",
      "[SKIP] Missing folder: C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\psmi\\eps05\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# USER INPUT\n",
    "# ============================================================\n",
    "BASE_DIR = r\"C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\"\n",
    "\n",
    "MECHS = [\"plm\", \"psm\", \"psmi\"]          # subfolders\n",
    "EPS_FOLDERS = [\"eps01\", \"eps05\"]       # eps subfolders to process (add more if needed)\n",
    "\n",
    "# If you want deterministic ordering:\n",
    "# - If filenames contain numbers, lexicographic is usually OK (e.g., user_001.csv < user_010.csv)\n",
    "# - For strict \"natural\" ordering, see note below.\n",
    "SORT_FILES = True\n",
    "\n",
    "\n",
    "def merge_csvs_in_folder(folder_path: str) -> pd.DataFrame:\n",
    "    csv_paths = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    if not csv_paths:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if SORT_FILES:\n",
    "        csv_paths = sorted(csv_paths)\n",
    "\n",
    "    dfs = []\n",
    "    for p in csv_paths:\n",
    "        df = pd.read_csv(p)\n",
    "        dfs.append(df)\n",
    "\n",
    "    merged = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    return merged\n",
    "\n",
    "\n",
    "for mech in MECHS:\n",
    "    mech_dir = os.path.join(BASE_DIR, mech)\n",
    "\n",
    "    for eps_folder in EPS_FOLDERS:\n",
    "        eps_dir = os.path.join(mech_dir, eps_folder)\n",
    "\n",
    "        if not os.path.isdir(eps_dir):\n",
    "            print(f\"[SKIP] Missing folder: {eps_dir}\")\n",
    "            continue\n",
    "\n",
    "        merged_df = merge_csvs_in_folder(eps_dir)\n",
    "        if merged_df.empty:\n",
    "            print(f\"[SKIP] No CSV files in: {eps_dir}\")\n",
    "            continue\n",
    "\n",
    "        # Build output folder name exactly as you requested\n",
    "        # Example:\n",
    "        # ...\\plm\\merged_geotrace_plm_delta_3_Noisy_threshold_5_eps01\n",
    "        out_folder_name = f\"merged_geotrace_{mech}_delta_3_Noisy_threshold_5_{eps_folder}\"\n",
    "        out_dir = os.path.join(mech_dir, out_folder_name)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        # Output file name (inside that folder)\n",
    "        # You can change this if you want a different name.\n",
    "        out_csv_path = os.path.join(out_dir, f\"{out_folder_name}.csv\")\n",
    "\n",
    "        merged_df.to_csv(out_csv_path, index=False)\n",
    "        print(f\"[OK] Merged {mech}/{eps_folder}: {len(merged_df)} rows -> {out_csv_path}\")\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceb9cb99-f3a3-4253-a4a6-71207b07098d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] plm/eps01: 63771 rows -> C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\plm\\merged_geotrace_plm_delta_3_Noisy_threshold_5_eps01.csv\n",
      "[SKIP] Missing eps folder: C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\plm\\eps05\n",
      "[OK] psm/eps01: 63771 rows -> C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\psm\\merged_geotrace_psm_delta_3_Noisy_threshold_5_eps01.csv\n",
      "[SKIP] Missing eps folder: C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\psm\\eps05\n",
      "[OK] psmi/eps01: 63771 rows -> C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\psmi\\merged_geotrace_psmi_delta_3_Noisy_threshold_5_eps01.csv\n",
      "[SKIP] Missing eps folder: C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\psmi\\eps05\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# USER INPUT\n",
    "# ============================================================\n",
    "BASE_DIR = r\"C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\"\n",
    "\n",
    "MECHS = [\"plm\", \"psm\", \"psmi\"]\n",
    "EPS_FOLDERS = [\"eps01\", \"eps05\"]  # add more if needed\n",
    "\n",
    "USE_NATURAL_SORT = True\n",
    "\n",
    "\n",
    "def natural_key(path: str):\n",
    "    name = os.path.basename(path)\n",
    "    return [int(t) if t.isdigit() else t.lower() for t in re.split(r\"(\\d+)\", name)]\n",
    "\n",
    "\n",
    "def merge_csvs_in_folder(folder_path: str) -> pd.DataFrame:\n",
    "    csv_paths = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    if not csv_paths:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if USE_NATURAL_SORT:\n",
    "        csv_paths = sorted(csv_paths, key=natural_key)\n",
    "    else:\n",
    "        csv_paths = sorted(csv_paths)\n",
    "\n",
    "    dfs = [pd.read_csv(p) for p in csv_paths]\n",
    "    return pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "for mech in MECHS:\n",
    "    mech_dir = os.path.join(BASE_DIR, mech)\n",
    "    if not os.path.isdir(mech_dir):\n",
    "        print(f\"[SKIP] Missing mech folder: {mech_dir}\")\n",
    "        continue\n",
    "\n",
    "    for eps_folder in EPS_FOLDERS:\n",
    "        eps_dir = os.path.join(mech_dir, eps_folder)\n",
    "        if not os.path.isdir(eps_dir):\n",
    "            print(f\"[SKIP] Missing eps folder: {eps_dir}\")\n",
    "            continue\n",
    "\n",
    "        merged_df = merge_csvs_in_folder(eps_dir)\n",
    "        if merged_df.empty:\n",
    "            print(f\"[SKIP] No CSV files in: {eps_dir}\")\n",
    "            continue\n",
    "\n",
    "        # Save DIRECTLY in plm/psm/psmi folder (NOT in a new subfolder)\n",
    "        out_name = f\"merged_geotrace_{mech}_delta_3_Noisy_threshold_5_{eps_folder}.csv\"\n",
    "        out_csv_path = os.path.join(mech_dir, out_name)\n",
    "\n",
    "        merged_df.to_csv(out_csv_path, index=False)\n",
    "        print(f\"[OK] {mech}/{eps_folder}: {len(merged_df)} rows -> {out_csv_path}\")\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a4924f-d4c5-40bf-a7a7-a17f47e33952",
   "metadata": {},
   "outputs": [],
   "source": [
    "now i have this merged csv file and i want to do some machine learning thing on it. for the csv file, you will find many columns, but the one that you want to discretize is latitude and longitude\n",
    "\n",
    "so basically latitude and longitude anre perturbed to perturbed_latitude and perturbed_longitude\n",
    "\n",
    "so i want to discretize (latitude and longitude) to location_id, so 2d to 1d, now my machine learnings task is to find location_id to perturtbed latiutude and longuitude\n",
    "\n",
    "so for this what you ahve to do is discretize latitude and longitude to location id and add id number in the column for , give too corasegridding many different lcoation pair would be in the same location id, if coarse then the opposite. \n",
    "\n",
    "def lat_lon_to_grid_pos(lat, lon, min_lat, max_lat, min_lon, max_lon, grid_size):\n",
    "    lat_step = (max_lat - min_lat) / grid_size\n",
    "    lon_step = (max_lon - min_lon) / grid_size\n",
    "    \n",
    "    # Calculate grid positions, clamping to the grid size - 1\n",
    "    lat_pos = min(int((lat - min_lat) / lat_step), grid_size - 1)\n",
    "    lon_pos = min(int((lon - min_lon) / lon_step), grid_size - 1)\n",
    "    \n",
    "    # Convert 2D grid position to a single integer\n",
    "    grid_pos = lat_pos * grid_size + lon_pos\n",
    "    return grid_pos\n",
    "\n",
    "def encode_locations(df, num_lat_bins, num_lon_bins):\n",
    "    \"\"\"\n",
    "    Encode latitude and longitude into a fixed-size grid and calculate the average\n",
    "    latitude and longitude for each grid cell.\n",
    "    \"\"\"\n",
    "    lat_min, lat_max = df['latitude'].min(), df['latitude'].max()\n",
    "    lon_min, lon_max = df['longitude'].min(), df['longitude'].max()\n",
    "\n",
    "    lat_bins = np.linspace(lat_min, lat_max, num_lat_bins + 1)\n",
    "    lon_bins = np.linspace(lon_min, lon_max, num_lon_bins + 1)\n",
    "\n",
    "    df['lat_bin'] = pd.cut(df['latitude'], bins=lat_bins, labels=False, include_lowest=True)\n",
    "    df['lon_bin'] = pd.cut(df['longitude'], bins=lon_bins, labels=False, include_lowest=True)\n",
    "    \n",
    "    df['location_id'] = df['lat_bin'] * num_lon_bins + df['lon_bin'] + 1\n",
    "\n",
    "    return df\n",
    "\n",
    "this is some code that i have which may be wrong, your task is to give me the accurate code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
