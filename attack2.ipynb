{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "464313c3-a604-4938-9154-fc5c397e40f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plm: loaded 63,771 rows from C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\plm\\merged_geotrace_plm_delta_3_Noisy_threshold_5_eps01.csv\n",
      "psmi: loaded 63,771 rows from C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\psmi\\merged_geotrace_psmi_delta_3_Noisy_threshold_5_eps01.csv\n",
      "plm L=2: BayesRisk=0.8446\n",
      "psmi L=2: BayesRisk=0.8309\n",
      "\n",
      "=== RESULTS ===\n",
      "mechanism  L  BayesRisk_HMM\n",
      "      plm  2       0.844585\n",
      "     psmi  2       0.830917\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# ============================================================\n",
    "# EDIT THESE PATHS (like your kNN script)\n",
    "# ============================================================\n",
    "\n",
    "PSMI_CSV = r\"C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\psmi\\merged_geotrace_psmi_delta_3_Noisy_threshold_5_eps01.csv\"\n",
    "PLM_CSV = r\"C:\\Users\\ss6365\\Desktop\\PrivAR_PSM_PSM_I\\data\\distorted_only_privacy\\geotrace\\delta_3_Noisy_threshold_5\\perturbed_1\\plm\\merged_geotrace_plm_delta_3_Noisy_threshold_5_eps01.csv\"\n",
    "\n",
    "MECHS = {\n",
    "    \"plm\": PLM_CSV,\n",
    "    # \"psm\": PSM_CSV,\n",
    "    \"psmi\": PSMI_CSV\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# SETTINGS\n",
    "# ============================================================\n",
    "TRACE_LENGTHS = [2]\n",
    "\n",
    "GRID_G = 200          # grid resolution for HMM state space: GxG\n",
    "R_NEIGH = 2           # neighbor radius for sparse transitions\n",
    "EMISSION_B = 0.0005   # emission bandwidth (in degrees)\n",
    "\n",
    "TEST_SIZE = 0.30\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# ============================================================\n",
    "# COLUMN NAMES IN YOUR MERGED CSV\n",
    "# ============================================================\n",
    "COL_TRUE_LAT = \"latitude\"\n",
    "COL_TRUE_LON = \"longitude\"\n",
    "COL_ID       = \"identifier\"\n",
    "COL_Z_LAT    = \"perturbed_latitude\"\n",
    "COL_Z_LON    = \"perturbed_longitude\"\n",
    "\n",
    "# ============================================================\n",
    "# LOADING + PREP\n",
    "# ============================================================\n",
    "def load_merged_from_path(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # keep only required columns\n",
    "    df = df[[COL_TRUE_LAT, COL_TRUE_LON, COL_ID, COL_Z_LAT, COL_Z_LON]].copy()\n",
    "    df.rename(columns={\n",
    "        COL_TRUE_LAT: \"true_lat\",\n",
    "        COL_TRUE_LON: \"true_lon\",\n",
    "        COL_ID: \"traj_id\",\n",
    "        COL_Z_LAT: \"z_lat\",\n",
    "        COL_Z_LON: \"z_lon\",\n",
    "    }, inplace=True)\n",
    "\n",
    "    # ensure traj_id is integer-like\n",
    "    df[\"traj_id\"] = df[\"traj_id\"].astype(int)\n",
    "\n",
    "    # assume rows already time-ordered within each traj_id; set an explicit time index\n",
    "    df[\"time\"] = df.groupby(\"traj_id\").cumcount()\n",
    "\n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# GRID MAPPING\n",
    "# ============================================================\n",
    "def fit_grid_bounds(all_true_lat, all_true_lon, G=GRID_G, pad_ratio=0.01):\n",
    "    lat_min, lat_max = float(np.min(all_true_lat)), float(np.max(all_true_lat))\n",
    "    lon_min, lon_max = float(np.min(all_true_lon)), float(np.max(all_true_lon))\n",
    "    lat_pad = (lat_max - lat_min) * pad_ratio + 1e-12\n",
    "    lon_pad = (lon_max - lon_min) * pad_ratio + 1e-12\n",
    "    return (lat_min - lat_pad, lat_max + lat_pad,\n",
    "            lon_min - lon_pad, lon_max + lon_pad, G)\n",
    "\n",
    "def to_cell(lat, lon, grid_params):\n",
    "    lat_min, lat_max, lon_min, lon_max, G = grid_params\n",
    "    r = np.floor((lat - lat_min) / (lat_max - lat_min) * G).astype(int)\n",
    "    c = np.floor((lon - lon_min) / (lon_max - lon_min) * G).astype(int)\n",
    "    r = np.clip(r, 0, G - 1)\n",
    "    c = np.clip(c, 0, G - 1)\n",
    "    return (r * G + c).astype(int)\n",
    "\n",
    "def build_neighbor_list(G, R):\n",
    "    neigh = []\n",
    "    for r in range(G):\n",
    "        for c in range(G):\n",
    "            r0 = max(0, r - R); r1 = min(G - 1, r + R)\n",
    "            c0 = max(0, c - R); c1 = min(G - 1, c + R)\n",
    "            lst = [rr * G + cc for rr in range(r0, r1 + 1)\n",
    "                               for cc in range(c0, c1 + 1)]\n",
    "            neigh.append(np.array(lst, dtype=int))\n",
    "    return neigh\n",
    "\n",
    "# ============================================================\n",
    "# HMM COMPONENTS\n",
    "# ============================================================\n",
    "def estimate_transition_sparse(df_train, grid_params, R=R_NEIGH, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Build sparse transition A(prev->next) using TRUE locations, restricted to neighbor set.\n",
    "    alpha is Dirichlet/Laplace smoothing within neighbor set.\n",
    "    \"\"\"\n",
    "    _, _, _, _, G = grid_params\n",
    "    neigh = build_neighbor_list(G, R)\n",
    "    counts = [dict() for _ in range(G * G)]\n",
    "\n",
    "    # IMPORTANT: enforce ordering by time within each trajectory\n",
    "    df_train = df_train.sort_values([\"traj_id\", \"time\"], kind=\"stable\")\n",
    "\n",
    "    for _, g in df_train.groupby(\"traj_id\", sort=False):\n",
    "        s = to_cell(g[\"true_lat\"].to_numpy(), g[\"true_lon\"].to_numpy(), grid_params)\n",
    "        for t in range(1, len(s)):\n",
    "            i, j = int(s[t-1]), int(s[t])\n",
    "            counts[i][j] = counts[i].get(j, 0) + 1\n",
    "\n",
    "    A_sparse = []\n",
    "    for i in range(G * G):\n",
    "        js = neigh[i]\n",
    "        vals = np.array([counts[i].get(int(j), 0.0) for j in js], dtype=float) + alpha\n",
    "        vals /= np.sum(vals)\n",
    "        A_sparse.append((js, vals))\n",
    "    return A_sparse, neigh\n",
    "\n",
    "def cell_centers(states, grid_params):\n",
    "    lat_min, lat_max, lon_min, lon_max, G = grid_params\n",
    "    r = states // G\n",
    "    c = states % G\n",
    "    return (lat_min + (r + 0.5) * (lat_max - lat_min) / G,\n",
    "            lon_min + (c + 0.5) * (lon_max - lon_min) / G)\n",
    "\n",
    "def emission_probs(zlat, zlon, cand_states, grid_params):\n",
    "    clat, clon = cell_centers(cand_states, grid_params)\n",
    "    d = np.sqrt((zlat - clat) ** 2 + (zlon - clon) ** 2)\n",
    "    w = np.exp(-d / EMISSION_B)\n",
    "    s = np.sum(w)\n",
    "    return w / s if s > 0 else np.ones_like(w) / len(w)\n",
    "\n",
    "def posterior_last_step(zlats, zlons, A_sparse, neigh, grid_params):\n",
    "    \"\"\"\n",
    "    Forward filtering over a sliding window, returning posterior over candidate states at last time step.\n",
    "    Uses a dynamic candidate expansion to keep it sparse.\n",
    "    \"\"\"\n",
    "    # init candidates around first observation\n",
    "    s0 = to_cell(np.array([zlats[0]]), np.array([zlons[0]]), grid_params)[0]\n",
    "    cand = neigh[int(s0)]\n",
    "    alpha_vec = emission_probs(zlats[0], zlons[0], cand, grid_params)\n",
    "\n",
    "    for t in range(1, len(zlats)):\n",
    "        # expand next candidate set\n",
    "        next_set = sorted(set(int(j) for s in cand for j in neigh[int(s)]))\n",
    "        next_set = np.array(next_set, dtype=int)\n",
    "        idx = {s: i for i, s in enumerate(next_set)}\n",
    "\n",
    "        pred = np.zeros(len(next_set), dtype=float)\n",
    "\n",
    "        for i, s in enumerate(cand):\n",
    "            js, ps = A_sparse[int(s)]\n",
    "            # js are within neighbor list of s\n",
    "            for j, p in zip(js, ps):\n",
    "                pred[idx[int(j)]] += alpha_vec[i] * p\n",
    "\n",
    "        # multiply by emission\n",
    "        emis = emission_probs(zlats[t], zlons[t], next_set, grid_params)\n",
    "        alpha_vec = pred * emis\n",
    "        ssum = np.sum(alpha_vec)\n",
    "        if ssum <= 0:\n",
    "            alpha_vec = np.ones_like(alpha_vec) / len(alpha_vec)\n",
    "        else:\n",
    "            alpha_vec /= ssum\n",
    "\n",
    "        cand = next_set\n",
    "\n",
    "    return alpha_vec  # posterior over \"cand\" at last step\n",
    "\n",
    "def bayes_risk_hmm(df_test, L, grid_params, A_sparse, neigh):\n",
    "    \"\"\"\n",
    "    Risk per time t is 1 - max_s posterior(s_t | z_{t-L+1:t}).\n",
    "    Average over all t and all test trajectories.\n",
    "    \"\"\"\n",
    "    df_test = df_test.sort_values([\"traj_id\", \"time\"], kind=\"stable\")\n",
    "\n",
    "    risks = []\n",
    "    for _, g in df_test.groupby(\"traj_id\", sort=False):\n",
    "        zlat = g[\"z_lat\"].to_numpy()\n",
    "        zlon = g[\"z_lon\"].to_numpy()\n",
    "        if len(g) < L:\n",
    "            continue\n",
    "        for t in range(L - 1, len(g)):\n",
    "            post = posterior_last_step(\n",
    "                zlat[t - L + 1 : t + 1],\n",
    "                zlon[t - L + 1 : t + 1],\n",
    "                A_sparse, neigh, grid_params\n",
    "            )\n",
    "            risks.append(1.0 - float(np.max(post)))\n",
    "\n",
    "    return float(np.mean(risks)) if risks else np.nan\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RUN\n",
    "# ============================================================\n",
    "data = {}\n",
    "for mech, path in MECHS.items():\n",
    "    df = load_merged_from_path(path)\n",
    "    data[mech] = df\n",
    "    print(f\"{mech}: loaded {len(df):,} rows from {path}\")\n",
    "\n",
    "# shared grid bounds across all mechanisms (fair comparison)\n",
    "grid_params = fit_grid_bounds(\n",
    "    np.concatenate([data[m][\"true_lat\"].to_numpy() for m in MECHS]),\n",
    "    np.concatenate([data[m][\"true_lon\"].to_numpy() for m in MECHS]),\n",
    ")\n",
    "\n",
    "rows = []\n",
    "for mech in MECHS:\n",
    "    df = data[mech]\n",
    "\n",
    "    splitter = GroupShuffleSplit(\n",
    "        n_splits=1,\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "    train_idx, test_idx = next(splitter.split(df, groups=df[\"traj_id\"]))\n",
    "    df_train, df_test = df.iloc[train_idx].copy(), df.iloc[test_idx].copy()\n",
    "\n",
    "    # estimate sparse transitions from training true states\n",
    "    A_sparse, neigh = estimate_transition_sparse(df_train, grid_params, R=R_NEIGH, alpha=1.0)\n",
    "\n",
    "    for L in TRACE_LENGTHS:\n",
    "        risk = bayes_risk_hmm(df_test, L, grid_params, A_sparse, neigh)\n",
    "        rows.append({\"mechanism\": mech, \"L\": L, \"BayesRisk_HMM\": risk})\n",
    "        print(f\"{mech} L={L}: BayesRisk={risk:.4f}\")\n",
    "\n",
    "res = pd.DataFrame(rows).sort_values([\"mechanism\", \"L\"])\n",
    "print(\"\\n=== RESULTS ===\")\n",
    "print(res.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30630fd9-aa3a-4b4b-b484-75ef9164b967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
